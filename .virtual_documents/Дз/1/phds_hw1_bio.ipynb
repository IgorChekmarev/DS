





# Bot check

# HW_ID: phds_hw1
# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.

# Status: final
# Перед отправкой в финальном решении удали "not" в строчке выше.
# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.
# Никакие значения в этой ячейке не влияют на факт сдачи работы.

# Profile: Biology











import numpy as np
size = 300 # размер выборки
samples_count = 1000  # количество выборок
all_samples = []
for i in range(samples_count):

    
    sample = np.random.exponential(scale = 1, size = size)

    all_samples.append(sample)
print(len(all_samples))





sums = []
for j in range(samples_count):
    sp_summ = np.array([])
    for i in range(size):
        summa = np.sum(all_samples[j][:i+1])
        sp_summ = np.append(sp_summ, summa)
    sums.append(sp_summ)
#print((sums[1]))





z = []
for j in range(samples_count):
    zj = np.array([])
    for n in range(1, size + 1):
        EX = n                          # так как Exi = 1
        stdX = np.sqrt(n)               # так как Dxi = 1
        zjn = (sums[j][n-1] - EX) / stdX
        zj = np.append(zj, zjn)
    z.append(zj)





import matplotlib.pyplot as plt
n = np.arange(300)
for i in range(1000):
    plt.plot(n, z[i], alpha=0.05)
plt.show()





zzz = np.array([])
for i in range(1000):
    zzz = np.append(zzz, z[i][299])
plt.hist(zzz, bins = 50, density=True, label = "Распределение случайных величин")

import matplotlib.pyplot as plt
from scipy import stats

x = np.linspace(-4, 4, 1000)

pdf = stats.norm.pdf(x, loc=0, scale=1)
plt.plot(x, pdf, label = "Нормальное распределение")
plt.legend()
plt.show()





import numpy as np
size = 300 # размер выборки
samples_count = 1000  # количество выборок
all_samples = []
for i in range(samples_count):

    
    sample = np.random.poisson(lam=1, size = size)

    all_samples.append(sample)
print(len(all_samples))

sums = []
for j in range(samples_count):
    sp_summ = np.array([])
    for i in range(size):
        summa = np.sum(all_samples[j][:i+1])
        sp_summ = np.append(sp_summ, summa)
    sums.append(sp_summ)
#print((sums[1]))

z = []
for j in range(samples_count):
    zj = np.array([])
    for n in range(1, size + 1):
        EX = n                   # nλ
        stdX = np.sqrt(n)        # √(nλ)
        zjn = (sums[j][n-1] - EX) / stdX
        zj = np.append(zj, zjn)
    z.append(zj)

import matplotlib.pyplot as plt
n = np.arange(300)
for i in range(1000):
    plt.plot(n, z[i], alpha=0.05)
plt.show()

zzz = np.array([])
for i in range(1000):
    zzz = np.append(zzz, z[i][299])
plt.hist(zzz, bins = 50, density=True, label = "Распределение случайных величин")

import matplotlib.pyplot as plt
from scipy import stats

x = np.linspace(-4, 4, 1000)

pdf = stats.norm.pdf(x, loc=0, scale=1)
plt.plot(x, pdf, label = "Нормальное распределение")
plt.legend()
plt.show()











import numpy as np
from scipy import stats

mean_time = 200
n = 100
time = 180
lambda_exp = 1 / mean_time
div = mean_time**2
X = np.sqrt(div / n)
z = (time - mean_time) / X
ver = 1 - stats.norm.cdf(z)
print(ver)








# загружаю библиотеки с семианара (Ctrl C Ctrl V)
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# обратите внимание, что Scikit-Learn импортируется как sklearn
from sklearn import datasets
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# фиксируем seed для воспроизводимости результатов
random_state = 42


anemia = pd.read_csv("Test_Anemia.csv")
anemia.head()





features_columns = ["GENDER", "Hemoglobin", "MCH", "MCHC", "MCV"]
target_column = "IDENTIFICATION"  # Целевой признак

X, y = anemia[features_columns], anemia[target_column]





X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)





anemia_train =  pd.concat([X_train, y_train], axis=1) 
anemia_train

anemia_train_male = anemia_train[anemia_train['GENDER'] == 0]
anemia_train_female = anemia_train[anemia_train['GENDER'] == 1]

anemia_train_male

anemia_train_pos = anemia_train[anemia_train['IDENTIFICATION'] == 1]
anemia_train_neg = anemia_train[anemia_train['IDENTIFICATION'] == 0]


from mpl_toolkits.mplot3d import Axes3D

plt.scatter(anemia_train["GENDER"], anemia_train[target_column])
plt.title("Влияние пола на анемию")
plt.show()
plt.scatter(anemia_train["Hemoglobin"], anemia_train[target_column])
plt.title("Влияние гемоглобина в крови на анемию")
plt.show()
plt.scatter(anemia_train["MCH"], anemia_train[target_column])
plt.title("Влияние гемоглобина в эритроците на анемию")
plt.show()
plt.scatter(anemia_train["MCHC"], anemia_train[target_column])
plt.title("Влияние концентрации гемоглобина в эритроците на анемию")
plt.show()
plt.scatter(anemia_train["MCV"], anemia_train[target_column])
plt.title("Влияние среднего объема эритроцита на анемию")
plt.show()


plt.show()
plt.scatter(anemia_train_male["Hemoglobin"], anemia_train_male[target_column])
plt.title("Влияние гемоглобина в крови на анемию у мужчин")
plt.show()
plt.scatter(anemia_train_male["MCH"], anemia_train_male[target_column])
plt.title("Влияние гемоглобина в эритроците на анемию у мужчин")
plt.show()
plt.scatter(anemia_train_male["MCHC"], anemia_train_male[target_column])
plt.title("Влияние концентрации гемоглобина в эритроците на анемию у мужчин")
plt.show()
plt.scatter(anemia_train_male["MCV"], anemia_train_male[target_column])
plt.title("Влияние среднего объема эритроцита на анемию у мужчин")
plt.show()


plt.show()
plt.scatter(anemia_train_female["Hemoglobin"], anemia_train_female[target_column])
plt.title("Влияние гемоглобина в крови на анемию у женщин")
plt.show()
plt.scatter(anemia_train_female["MCH"], anemia_train_female[target_column])
plt.title("Влияние гемоглобина в эритроците на анемию у женщин")
plt.show()
plt.scatter(anemia_train_female["MCHC"], anemia_train_female[target_column])
plt.title("Влияние концентрации гемоглобина в эритроците на анемию у женщин")
plt.show()
plt.scatter(anemia_train_female["MCV"], anemia_train_female[target_column])
plt.title("Влияние среднего объема эритроцита на анемию у женщин")
plt.show()

plt.scatter(anemia_train_pos['MCHC'], anemia_train_pos['MCV'],  label = "Анемия есть")
plt.scatter(anemia_train_neg['MCHC'], anemia_train_neg['MCV'], label = "Анемии нет")
plt.title("Кластеризация наличия анемии от концентрации гемоглобина в эритроците и объема эритроцитов") # это я решил посмотреть на кластеры от 2 признаков сразу, надеялся, что что-то даст (я перепробовал все 6 комбинаций, но только гемоглобин что-то дает)
plt.legend()
plt.show()

anemia_train_male_pos = anemia_train_male[anemia_train_male['IDENTIFICATION'] == 1]
anemia_train_male_neg = anemia_train_male[anemia_train_male['IDENTIFICATION'] == 0]
print(max(anemia_train_male_pos["Hemoglobin"]))
print(min(anemia_train_male_neg["Hemoglobin"]))

anemia_train_female_pos = anemia_train_female[anemia_train_female['IDENTIFICATION'] == 1]
anemia_train_female_neg = anemia_train_female[anemia_train_female['IDENTIFICATION'] == 0]
print(max(anemia_train_female_pos["Hemoglobin"]))
print(min(anemia_train_female_neg["Hemoglobin"]))








def tree(features: pd.DataFrame) -> pd.Series:
    """
    Предсказание целевого признака для данных features -- pandas-таблица данных.
    Возвращает pandas.Series с теми же индексами, что и у features.
    """

    ...
    return predicted





def accuracy(target: pd.Series, predicted: pd.Series) -> float:
    """
    Вычисление критерия качества для предсказания predicted,
    если истинные значения -- target.
    Возвращает одно вещественное число.
    """

    ...


...





# взял код с семинара

accs_train = []
accs_test = []

for k in range(1,21):
  knn =  KNeighborsClassifier(n_neighbors = k)# инициализация модели
  knn.fit(X_train, y_train) # обучения модели
  y_train_pred = knn.predict(X_train)
  acc_train = accuracy_score(y_train, y_train_pred)  
  accs_train.append(acc_train) # предсказание модели и расчет метрик
  y_test_pred = knn.predict(X_test)
  acc_test = accuracy_score(y_test, y_test_pred)
  accs_test.append(acc_test)


# взял код с семинара

plt.figure(figsize=(12,6))
x = np.arange(1, 21)
plt.plot(x,accs_train, label = 'тренировка')
plt.plot(x,accs_test, label = 'тест')
plt.legend()
plt.xticks(range(1,20))
plt.xlabel(r'Число соседей $k$')
plt.ylabel('Accuracy');





for i in features_columns:
    print(min(anemia_train[i]), max(anemia_train[i]))

















from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

anemia_ready = scaler.fit_transform(anemia)





print(anemia_ready)
for i in range(5):
    print(min(anemia_ready[:,i]), max(anemia_ready[:,i]))





features = anemia_ready[:,0:5]
target = anemia_ready[:, 5]


accs_train1 = []
accs_test1 = []

A_train, A_test, b_train, b_test = train_test_split(features, target, test_size = 0.3)
for k in range(1,21):
  knn =  KNeighborsClassifier(n_neighbors = k)# инициализация модели
  knn.fit(A_train, b_train) # обучения модели
  b_train_pred = knn.predict(A_train)
  acc_train1 = accuracy_score(b_train, b_train_pred)  
  accs_train1.append(acc_train1) # предсказание модели и расчет метрик
  b_test_pred = knn.predict(A_test)
  acc_test1 = accuracy_score(b_test, b_test_pred)
  accs_test1.append(acc_test1)


plt.figure(figsize=(12,6))
x = np.arange(1, 21)
plt.plot(x,accs_train1, label = 'тренировка')
plt.plot(x,accs_test1, label = 'тест')
plt.legend()
plt.xticks(range(1,20))
plt.xlabel(r'Число соседей $k$')
plt.ylabel('Accuracy');








#смотри предыдущую ячейку с кодом - я сразу сделал график для сравнения точностей вместе с обучением модели для наглядности















