


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.utils import resample
from math import ceil

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report


import seaborn as sns
from matplotlib.colors import LinearSegmentedColormap
from typing import Sequence, Tuple

sns.set_theme(style='dark', font_scale=1.3)

import warnings
warnings.filterwarnings('ignore')











data = pd.read_csv('Test_Anemia_final.csv')





data.head()


data.describe()


data.info()








data.dropna()





X = data[['Hemoglobin', 'MCH', 'MCHC', 'MCV', 'GENDER', 'MSE', 'RDI', 'PVI', ]]
y = data['IDENTIFICATION']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)











logreg = LogisticRegression(random_state=0, penalty=None)





logreg.fit(X_train, y_train)





y_pred_log_train = logreg.predict(X_train)
y_pred_log_test  = logreg.predict(X_test)

acc_train = accuracy_score(y_train, y_pred_log_train)  
acc_test = accuracy_score(y_test, y_pred_log_test)

print(np.round(acc_train, 3))
print(np.round(acc_test, 3))





data.info()

sns.kdeplot(X_test)











y_pred_proba = logreg.predict_proba(X_test)

data = pd.DataFrame(y_pred_proba, columns=['Probability_class_0', 'Probability_class_1'])
data['class'] = y_test.reset_index(drop=True)

data_rounded = data.copy()
data_rounded[['Probability_class_0','Probability_class_1']] = data_rounded[['Probability_class_0','Probability_class_1']].round(3)

data_rounded.head()















def plot_accuracy_threshold(prob_class_1: np.ndarray) -> None:

  """
    Строит зависимость accuracy от порога отсечения для вероятностей класса 1.

    Параметры
    ----------
    prob_class_1 : np.ndarraye of shape (n_samples,)
        Оценённые вероятности принадлежности к классу 1.
        Должны соответствовать тем же объектам, что и глобальная переменная `y_test`.

  """
  thresholds = np.linspace(0, 1, 1000)
  accur = []
  for i in thresholds:
      y_preds = prob_class_1>i

      accur.append(accuracy_score(y_test, y_preds))


  plt.figure(figsize=(18, 6))

  plt.plot(thresholds, accur, label='Standard Model', color='blue')
  plt.title('Accuracy Comparison (Clipped)')
  plt.xlabel('Threshold')
  plt.ylabel('Accuracy')
  plt.ylim(0.5, 1)

  plt.legend()
  plt.grid(True)

  plt.tight_layout()
  plt.show()





plot_accuracy_threshold(data['Probability_class_1'])











pred_1 = y_pred_log_test[:, 1]
pred_0 = y_pred_log_test[:, 0]

true_1 = y_test[:, 1]
true_0 = y_test[:, 0]










class_counts = y_train.value_counts()
order = sorted(class_counts.index)

plt.figure(figsize=(8, 6))
ax = sns.barplot(
    x=order,
    y=[class_counts[i] for i in order],
    palette="viridis"
)

plt.title("Сбалансированность классов", fontsize=16)
plt.xlabel("Класс", fontsize=14)
plt.ylabel("Количество примеров", fontsize=14)

for i, k in enumerate(order):
    ax.text(i, class_counts[k], str(class_counts[k]), ha="center", va="bottom")

plt.show()





# Вероятности класса 1
proba_class_1 = data["Probability_class_1"]

# Разделяем по истинным классам
proba_class_0 = proba_class_1[data["class"] == 0]
proba_class_1 = proba_class_1[data["class"] == 1]

plt.figure(figsize=(10, 5))
plt.hist(proba_class_0, bins = 20)
plt.hist(proba_class_1, bins = 20)
plt.axvline(0.5, color="red", linestyle="--", label="Порог 0.5")

plt.yscale('log')

plt.xlabel("Предсказанная вероятность класса 1")
plt.ylabel("Количество объектов (лог шкала)")
plt.title("Распределение предсказанных вероятностей по классам")
plt.legend()
plt.grid(True, which="both", axis="y", ls="--", alpha=0.6)
plt.tight_layout()
plt.show()















y = np.asarray(y_train).ravel()

# индексы каждого класса
idx0 = np.where(y == 0)[0]
idx1 = np.where(y == 1)[0]

# размер меньшего класса
n_min = min(len(idx0), len(idx1))

rng = np.random.default_rng(42)
idx0_ds = rng.choice(idx0, size=n_min, replace=False)
idx1_ds = rng.choice(idx1, size=n_min, replace=False)

# итоговые индексы (перемешаем)
idx_ds = np.concatenate([idx0_ds, idx1_ds])
rng.shuffle(idx_ds)

# downsampled train
X_train_bal = X_train.iloc[idx_ds]
y_train_bal = y[idx_ds]





sns.kdeplot(X_train_bal)
plt.show()

sns.kdeplot(y_train_bal)
plt.show()





logreg.fit(X_train_bal, y_train_bal)
y_pred_log_train_bal = logreg.predict(X_train_bal)
y_pred_log_test  = logreg.predict(X_test)

acc_train = accuracy_score(y_train_bal, y_pred_log_train_bal)  
acc_test = accuracy_score(y_test, y_pred_log_test)

print(np.round(acc_train, 3))
print(np.round(acc_test, 3))









